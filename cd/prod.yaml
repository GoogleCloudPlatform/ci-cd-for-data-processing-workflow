# Copyright 2019 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
steps:
# [Dataflow]
# Stage JARs on GCS.
- name: gcr.io/cloud-builders/gsutil
  args: [
          'cp',
          'gs://${_DATAFLOW_ARTIFACT_BUCKET}/${_CI_BUILD_ID}/wordcount.jar'
          'gs://${_DATAFLOW_JAR_BUCKET}/wordcount.jar']
  id: 'deploy-wordcount-jar'
# [BigQuery]
# Copy SQL to DAGs folder in prod.
- name: gcr.io/cloud-builders/gsutil
  waitFor: ['test-sql-queries']
  args: [
          'rsync','-r', '-d',
          'sql', '${_COMPOSER_DAG_BUCKET}dags/sql'
        ]
  dir: './bigquery/'
  id: 'deploy-sql-queries-for-composer'
# [Composer]
# Render AirflowVariables.json with production values
- name: 'gcr.io/${PROJECT_ID}/envsubst'
  waitFor: ['-']
  env: [
          "GCP_PROJECT_ID=${PROJECT_ID}",
          "COMPOSER_REGION=${_COMPOSER_REGION}",
          "DATAFLOW_JAR_BUCKET=${_DATAFLOW_JAR_BUCKET}",
          "INPUT_BUCKET=${_WORDCOUNT_INPUT_BUCKET}",
          "REF_BUCKET=${_WORDCOUNT_REF_BUCKET}",
          "RESULT_BUCKET=${_WORDCOUNT_RESULT_BUCKET}",
          "DATAFLOW_STAGING_BUCKET=${_DATAFLOW_STAGING_BUCKET}",
       ] 
  args: ['AirflowVariables.json']
  dir: './composer/config'
  id: 'render-airflow-variables'
# Add .airflowignore to GCS prod DAGs folder.
- name: gcr.io/cloud-builders/gcloud
  waitFor: ['run-unit-tests']
  args: [
          'composer', 'environments', 'storage', 'dags', 'import',
          '--source','.airflowignore',
          '--environment', '${_COMPOSER_ENV_NAME}',
          '--location', '${_COMPOSER_REGION}'
        ]
  dir: './composer/dags/'
  id: 'deploy-airflowignore'
# Stage AirflowVariables.json to data directory to be synced to workers.
- name: gcr.io/cloud-builders/gcloud
  waitFor: ['render-airflow-variables']
  args: [
          'composer', 'environments', 'storage', 'data', 'import',
          '--location=${_COMPOSER_REGION}',
          '--environment=${_COMPOSER_ENV_NAME}',
          '--source','AirflowVariables.json',
          '--destination', 'config'
        ]
  dir: './composer/config/'
  id: 'stage-airflow-variables'
# Import AirflowVariables.json 
- name: gcr.io/cloud-builders/gcloud
  waitFor: ['stage-airflow-variables']
  args: [
          'composer', 'environments', 'run', 
          '--location=${_COMPOSER_REGION}',
          '${_COMPOSER_ENV_NAME}',
          'variables', '--',
          '--import', '/home/airflow/gcs/data/config/AirflowVariables.json'
        ] 
  id: 'import-airflow-variables'
# Override JAR reference variable to the artifact built in this build.
- name: gcr.io/cloud-builders/gcloud
  args: [
          'composer', 'environments', 'run',
          '--location', '${_COMPOSER_REGION}',
          '${_COMPOSER_ENV_NAME}', 
          'variables', '--', 
          '--set', 'dataflow_jar_file_test', 'wordcount.jar'
        ]
  id: 'set-composer-test-jar-ref'
# Sync plugins to GCS plugins dir
- name: gcr.io/cloud-builders/gsutil
  args: [
          'rsync','-r', '-d',
          'plugins/',
          '${_COMPOSER_DAG_BUCKET}plugins'
        ]
  dir: './composer/'
  id: 'deploy-custom-plugins'
# Sync DAGs to data dir for integration test parsing in  target Composer Environment.
- name: gcr.io/cloud-builders/gsutil
  waitFor: ['deploy-custom-plugins']
  args: [
          'rsync','-r', '-d',
          'dags/',
          '${_COMPOSER_DAG_BUCKET}data/test-dags/$BUILD_ID'
        ]
  dir: './composer/'
  id: 'stage-for-integration-test'
# Run integration tests parsing in target Composer Environment.
- name: gcr.io/cloud-builders/gcloud
  waitFor: ['stage-for-integration-test']
  args: [
          'composer', 'environments', 'run', 
          '--location', '${_COMPOSER_REGION}',
          '${_COMPOSER_ENV_NAME}', 
          'list_dags', '--', 
          '-sd', '/home/airflow/gcs/data/test-dags/$BUILD_ID'
        ] 
  id: 'dag-parse-integration-test'
# Clean up. 
- name: gcr.io/cloud-builders/gsutil
  waitFor: ['dag-parse-integration-test']
  args: [
          '-m', 'rm','-r',
          '${_COMPOSER_DAG_BUCKET}data/test-dags/$BUILD_ID'
        ]
  dir: './composer/'
  id: 'clean-up-data-dir-dags'
# Run dags deployer golang app. 
- name: gcr.io/${_CI_PROJECT_ID}/deploydags
  dir: './composer'
  waitFor: [
          'run-style-and-unit-tests',
          'build-deploydags',
          'clean-up-data-dir-dags',
          'deploy-wordcount-jar'
          ]
  args: [
          '-dagList=./config/running_dags.txt',
          '-dagsFolder=./dags',
          '-project=${PROJECT_ID}',
          '-region=${_COMPOSER_REGION}',
          '-composerEnv=${_COMPOSER_ENV_NAME}',
          '-dagBucketPrefix=${_COMPOSER_DAG_BUCKET}dags',
          '-replace'
        ]
  id: 'run-deploydags'
options:
  machineType: 'N1_HIGHCPU_8'
